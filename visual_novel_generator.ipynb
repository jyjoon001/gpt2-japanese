{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "visual-novel-generator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPMOe5PwehxDglv88Q/BnxA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyjoon001/gpt2-japanese/blob/master/visual_novel_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6Fxv4WTRrJ2"
      },
      "source": [
        "# Visual Novel Generator\n",
        "\n",
        "이 GPT-2 모델은 사전 학습된 일어 GPT-2 모델에 일본어 텍스트 어드벤처 게임에서 추출된 약 20만줄의 정제된 텍스트 데이터를 전이학습하여 Fine-Tuning하였습니다. \n",
        "\n",
        "Pre-Trained Model과 Training을 위한 기반 코드는 [Japanese GPT2 Generation Model](https://github.com/tanreinama/gpt2-japanese) 을 사용하였습니다. \n",
        "> [@jyjoon001](https://github.com/jyjoon001) , forked from [tanreinama.](https://github.com/tanreinama) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-u_0TRhRqnj",
        "outputId": "fb469b28-1cf5-4955-8dc0-b6d7f91d21dc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HipI56hcYk_y"
      },
      "source": [
        "Google Drive에 파일이 있는지 확인하며 파일이 존재하지 않을 경우 Fine-Tune된 모델과 코드를 다운로드합니다. <br> 해당 파일은 1.1GB의 크기를 가지고 있습니다. \n",
        "* 적절한 웹호스팅 공간이 없어 임시로 Naver Mail 서버를 사용하고 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IpNYfLjCXFf9",
        "outputId": "d0a22a4e-4014-4b54-8896-081a51f27268"
      },
      "source": [
        "import os\n",
        "if os.path.isfile('/content/drive/MyDrive/visual-novel-generator/gpt2-generate.py') is True:\n",
        "    print('path found.')\n",
        "else:\n",
        "    print('path not found, downloading model.')\n",
        "    #!wget https://bigfile.mail.naver.com/bigfileupload/download?fid=pXR5Wre8D6cZHqujKxgmFoMdax2mHqUmKoumFqg9KxbwFqEdHqurKo2maAvwaxvjF634KzFoMqg9FqUwp6EmF6trF4EZpxFoK6EdFAK9Mov=\n",
        "    !unzip download?fid=pXR5Wre8D6cZHqujKxgmFoMdax2mHqUmKoumFqg9KxbwFqEdHqurKo2maAvwaxvjF634KzFoMqg9FqUwp6EmF6trF4EZpxFoK6EdFAK9Mov="
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "path found.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4NgjI4hg3r2"
      },
      "source": [
        "starting_word를 조정해서 생성 모델이 어떤 후속 문장을 생성할지를 정할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmg5VRvUXM78"
      },
      "source": [
        "starting_word = \"けれど、あなたは私に夢と希望をくれました。\" #그렇지만, 당신은 저에게 꿈과 희망을 주었습니다."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LW6XGhPhhKeu"
      },
      "source": [
        "필요한 코드를 실행시키기 위하여 필요한 라이브러리를 다운받습니다. \n",
        "</br> jaconv는 정제되지 않은 일어 데이터를 unicode 데이터로 normalize합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZalnoUJXRzj",
        "outputId": "cd4dc9ce-d532-4544-ba80-db3cf836a9e5"
      },
      "source": [
        "%cd /content/drive/MyDrive/visual-novel-generator/\n",
        "with open(\"prologue.txt\", \"w\") as output:\n",
        "     output.write(starting_word)\n",
        "!pip install jaconv"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/visual-novel-generator\n",
            "Collecting jaconv\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/c3/26e3c4121fce080594e4a714d8fac69c281e8159f65e4ad77188d9141e27/jaconv-0.3.tar.gz\n",
            "Building wheels for collected packages: jaconv\n",
            "  Building wheel for jaconv (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jaconv: filename=jaconv-0.3-cp37-none-any.whl size=15566 sha256=34a5d6e7fbdfe238e29c6b649c22f99bde4b67e79abce2da1a16a3ebb90155c1\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/c8/4d/c29135241814c9221027da775d00bcfead63bc924f8ccdaf41\n",
            "Successfully built jaconv\n",
            "Installing collected packages: jaconv\n",
            "Successfully installed jaconv-0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5cQh4bnsg5Zl"
      },
      "source": [
        "gpt2-generate.py를 통하여 소스 코드를 실행시킵니다. \n",
        "해당 gpt2-generate.py는 다음과 같은 형태로 이루어져 있습니다. \n",
        "* argparse를 통하여 argument를 설정합니다. 사용하는 model, 입력/출력 문장, 최대/최소 음절과 문장이 얼마나 임의의 단어를 생성하는지에 대한 temperature 계수, top-k 및 top-p sampling 시 사용하는 어절의 갯수 등을 결정합니다. \n",
        "* 사용하는 Model의 정보를 불러온 뒤 layer 갯수 등의 정보를 결정합니다. \n",
        "* generate_one 함수에서는 우선 입력 문장을 encode하여  Tensorflow session을 실행시켜 후속 토큰을 생성하며, 이를 decode하여 자연어로 출력한다. 이 때```'<|endoftext|>'``` 토큰이 나올 경우는 생성된 문장에 last 라벨링을 하여 문장의 끝을 알 수 있게 합니다. \n",
        "* Tensorflow session의 경우 sampling.py의 sample_sequence를 통해서 output을 결정합니다. 이후, max_length까지 위의 함수를 통하여 문장을 generate합니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 775
        },
        "id": "BBiex_g0XSxy",
        "outputId": "fc6cc411-d211-4a15-932f-670248ebcc24"
      },
      "source": [
        "!python3 gpt2-generate.py --num_generate 1 --temperature 1.5 --max_length 1024 --min_length 512\n",
        "from google.colab import files\n",
        "files.download(\"script.txt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-07-05 08:56:20.820634: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-05 08:56:24.344424: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
            "2021-07-05 08:56:24.392910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:24.393593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-05 08:56:24.393650: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-05 08:56:24.498935: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-05 08:56:24.499104: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
            "2021-07-05 08:56:24.652261: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
            "2021-07-05 08:56:24.686790: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
            "2021-07-05 08:56:24.954366: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.10\n",
            "2021-07-05 08:56:24.972071: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
            "2021-07-05 08:56:24.976706: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
            "2021-07-05 08:56:24.976860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:24.977536: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:24.980694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "2021-07-05 08:56:24.983396: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "2021-07-05 08:56:29.346620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2021-07-05 08:56:29.346676: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
            "2021-07-05 08:56:29.346691: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
            "2021-07-05 08:56:29.346851: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:29.347546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:29.348109: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:29.348646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13837 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\n",
            "WARNING:tensorflow:From /content/drive/MyDrive/visual-novel-generator/sampling.py:65: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "2021-07-05 08:56:33.982606: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:33.983251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
            "pciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\n",
            "coreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.75GiB deviceMemoryBandwidth: 298.08GiB/s\n",
            "2021-07-05 08:56:33.983356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:33.983891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2021-07-05 08:56:33.984398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.random.categorical` instead.\n",
            "2021-07-05 08:56:36.807525: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199995000 Hz\n",
            "2021-07-05 08:56:53.913508: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
            "2021-07-05 08:56:56.472538: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_9451a2dd-64ce-47c0-91f6-956448f0161e\", \"script.txt\", 2807)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}